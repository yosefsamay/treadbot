
import yfinance as yf
import pandas as pd
import numpy as np
import random
import os
import tensorflow as tf

from ta.momentum import RSIIndicator
from ta.trend import MACD
from ta.momentum import ROCIndicator
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import StandardScaler

# Set global random seeds for reproducibility
def set_seeds(seed=42):
    np.random.seed(seed)
    random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seeds()

LOOKAHEAD = 5

# Pre-screening using fast metadata only (no historical download yet)
def screen_candidates(all_tickers, min_market_cap=10e9, min_avg_volume=1e6):
    valid = []
    for ticker in all_tickers:
        try:
            info = yf.Ticker(ticker).info
            if (
                info.get("marketCap", 0) >= min_market_cap and
                info.get("averageVolume", 0) >= min_avg_volume
            ):
                valid.append(ticker)
        except:
            continue
    return valid

# Get top 100 tickers (SPY or broader index)
def get_top_spy_stocks():
    top_100 = [
        "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA", "BRK-B", "UNH", "JNJ",
        "XOM", "V", "JPM", "PG", "MA", "HD", "CVX", "LLY", "ABBV", "AVGO",
        "PEP", "MRK", "KO", "COST", "WMT", "BAC", "DIS", "ADBE", "CSCO", "MCD",
        "QCOM", "TMO", "DHR", "ACN", "ABT", "NEE", "TXN", "LIN", "PM", "BMY",
        "INTC", "AMD", "AMGN", "LOW", "UNP", "HON", "GS", "RTX", "CAT", "BLK"
    ]
    return top_100

# Download historical data only for valid tickers
def download_data(tickers):
    end_date = pd.Timestamp.today()
    start_date = end_date - pd.DateOffset(years=3)
    data = yf.download(tickers + ["^VIX", "SPY"], start=start_date, end=end_date, group_by='ticker', auto_adjust=False)
    adj_close = pd.DataFrame({ticker: data[ticker]['Adj Close'] for ticker in tickers if ticker in data.columns.get_level_values(0)})
    volume = pd.DataFrame({ticker: data[ticker]['Volume'] for ticker in tickers if ticker in data.columns.get_level_values(0)})
    vix = data['^VIX']['Adj Close'] if '^VIX' in data.columns.get_level_values(0) else pd.Series()
    spy = data['SPY']['Adj Close'] if 'SPY' in data.columns.get_level_values(0) else pd.Series()
    return adj_close, volume, vix, spy


def create_features(df, volume_series, vix, spy):
    features = pd.DataFrame(index=df.index)
    features['price'] = df
    features['returns'] = df.pct_change()
    features['sma_20'] = df.rolling(window=20).mean()
    features['sma_50'] = df.rolling(window=50).mean()
    features['sma_ratio'] = features['sma_20'] / features['sma_50']
    features['volatility'] = df.pct_change().rolling(window=20).std()
    features['macd'] = MACD(df).macd_diff()
    features['rsi'] = RSIIndicator(df).rsi()
    features['momentum'] = ROCIndicator(df).roc()
    features['momentum_signal'] = (features['momentum'] > 0).astype(int).rolling(window=5).mean()
    features['open'] = df.shift(1)
    features['close'] = df
    features['candle_signal'] = np.where(
        abs(features['close'] - features['open']) < 0.002 * features['open'], 0,
        np.where(features['close'] > features['open'], 1, -1)
    )
    features['volume'] = volume_series
    features['volume_sma_20'] = volume_series.rolling(window=20).mean()
    features['volume_ratio'] = volume_series / features['volume_sma_20']
    features['vix'] = vix.reindex(df.index).fillna(method='ffill')
    features['spy'] = spy.reindex(df.index).pct_change().fillna(0).rolling(window=5).mean()
    features['target'] = (df.shift(-LOOKAHEAD) > df).astype(int)
    return features.dropna()


def train_xgboost(X_train, y_train):
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    model.fit(X_train, y_train)
    return model


def train_lstm(X, y):
    model = Sequential()
    model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(50))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X, y, epochs=5, batch_size=32, verbose=0)
    return model


def recommend_stocks(adj_close_data, volume_data, vix, spy):
    recommendations = []

    for ticker in adj_close_data.columns:
        prices = adj_close_data[ticker].dropna()
        volume = volume_data[ticker].dropna()
        if len(prices) < 200 or len(volume) < 200:
            continue

        features = create_features(prices, volume, vix, spy)
        X = features.drop(['target', 'price'], axis=1)
        y = features['target']
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False, random_state=42)
        xgb_model = train_xgboost(X_train, y_train)
        lstm_X = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
        lstm_model = train_lstm(lstm_X, y_train)

        X_live = X_scaled[-1:]
        lstm_input = X_live.reshape((1, 1, X_live.shape[1]))

        xgb_prob = xgb_model.predict_proba(X_live)[0, 1]
        lstm_prob = lstm_model.predict(lstm_input)[0, 0]
        avg_prob = (xgb_prob + lstm_prob) / 2

        confidence = abs(avg_prob - 0.5)
        direction = "LONG" if avg_prob > 0.5 else "SHORT"
        candle_signal = features['candle_signal'].iloc[-1]

        if (direction == "LONG" and candle_signal == 1) or (direction == "SHORT" and candle_signal == -1):
            recommendations.append((ticker, direction, round(avg_prob, 3), round(confidence, 3)))

    recommendations.sort(key=lambda x: x[3], reverse=True)
    return recommendations[:2]


tickers = screen_candidates(get_top_spy_stocks())
adj_close_data, volume_data, vix_data, spy_data = download_data(tickers)
print("Loaded data for", len(adj_close_data.columns), "tickers")

best_stocks = recommend_stocks(adj_close_data, volume_data, vix_data, spy_data)
print("Top Stock Recommendations:")
for ticker, direction, prob, confidence in best_stocks:
    print(f"{ticker}: {direction} (prob={prob}, confidence={confidence})")
